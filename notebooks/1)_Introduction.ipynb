{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The hdf5 data file\n",
    "\n",
    "This notebook provides examples for accessing data within an oskar hdf5 datafile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from e11 import run_file, H5Scan, H5Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`run_file()`  \n",
    "    - A function that generates the path to the data file using the run ID and base directory.\n",
    "\n",
    "`H5Scan`\n",
    "    - A class that provides a convienient interface for simple hdf5 data files with no groups.\n",
    "`H5Data`  \n",
    "    - A class that provides a convienient interface for more complicated hdf5 data files with groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, the datafiles files would be saved in a timestamp structure and each can be found using the `rid`.  The path to the file can then be built using `run_file`.\n",
    "\n",
    "``` python\n",
    ">>> fil = run_file(base=\"Q:\\E11_atmos\\data\", rid='20171127_155753')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But for this example we'll use the example data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H5Scan\n",
    "\n",
    "`H5Scan` provides a very simple interface for files which only contain datasets (no groups)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "fil = os.path.join(os.getcwd(), 'example_data', 'microwave_scan.h5')\n",
    "scan = H5Scan(fil)\n",
    "# root attributes\n",
    "scan.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "To list the datasets found in the file, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or to get the attributes associated with a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.dataset_attrs('analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets can be accessed using `h5.array()`, for array data, or `h5.df()` for DataFrame data, e.g., "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.array('osc_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.df('analysis').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `2)_Raw_datasets.ipynb` for further examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H5Data\n",
    "\n",
    "More complicated files can be accessed using `H5Data`, which expects to find the datasets divided between groups.  `H5Data` is simular to `H5scan`, but it has a few extra features to help keep track of the relationship between groups and the datasets within them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = os.path.join(os.getcwd(), 'example_data', 'laser_data.h5')\n",
    "data = H5Data(fil)\n",
    "data.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `data` is an instance of the H5Data class.  Creating this instance generates a `pandas.DataFrame` summary of the group attributes called `data.log`.  This can be rebuilt using `data.update()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our case building the log doesn't take very long.\n",
    "%time data.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log output\n",
    "data.log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental settings are stored in the log file as VARS and measurements as RECS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from e11.tools import add_column_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine VAR and REC data\n",
    "df = add_column_index(data.var, 'VAR').join(add_column_index(data.rec, 'REC'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# data\n",
    "xvals = df[('VAR', 'WL?1')]    # laser wavelength PID reference\n",
    "yvals = df[('REC', 'WLM?2')]   # measured wavelength\n",
    "ax.scatter(xvals, yvals, marker='.')\n",
    "\n",
    "# format\n",
    "ax.set_xlim([xvals.min(), xvals.max()])\n",
    "ax.set_ylim([yvals.min(), yvals.max()])\n",
    "ax.set_xlabel('set wavelength (nm)')\n",
    "ax.set_ylabel('measured wavelength (nm)')\n",
    "\n",
    "# output\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groups\n",
    "\n",
    "The datasets are distributed within groups. Each group represents one configuration of experimental variables (VARS), and they are numbered sequentually by the `squid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.squids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To discover the settings relating to a particular group check the log,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squid = 1\n",
    "data.log.loc[squid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is equivilent to,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.group_attrs(squid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "To list the datasets in a particular group,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squid = 1\n",
    "print(data.datasets(squid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or to see the attributes of a particular dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dataset_attrs('WLM', squid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "See 'Raw datasets.ipynb' for examples for how to access the data within different types of hdf5 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching\n",
    "\n",
    "Often hdf5 files can be very large and processing them can take a long time.  To speed up future access, processing results can be cached.\n",
    "\n",
    "For this it is nessasry to specify an `out_dire` when creating the instance of `H5Scan` or `H5Data`, e.g.\n",
    "\n",
    "``` python\n",
    ">>> h5 = H5Data(fil, out_dire='analysis')\n",
    "```\n",
    "\n",
    "If `out_dire` is declared then the log will automatically be cached as a pickle file in `./[out_dire]/cache`.  By default, when reloading the file the cache will be used for the log, unless `update=True` is set.\n",
    "\n",
    "Caching can be applied to the methods: `array()`, `df()`, and `apply()`. \n",
    "\n",
    "Another use of `out_dire` is to build useful paths, e.g., for saving plots to a sub directory.\n",
    "\n",
    "``` python\n",
    ">>> out_fil = h5.sub_dire('plots', fname='signal.png')\n",
    ">>> plt.savefig(out_fil, bbox_inches='tight', dpi=200)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
