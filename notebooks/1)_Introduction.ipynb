{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The hdf5 data file\n",
    "\n",
    "This notebook provides examples for accessing data within an oskar hdf5 datafile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from e11 import run_file, H5Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`run_file()`  \n",
    "    - A function that generates the path to the data file using the run ID and base directory.\n",
    "\n",
    "`H5Data`  \n",
    "    - A class that provides a convienient interface for an oskar hdf5 data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, the datafiles files would be saved in a timestamp structure and each can be found using the `rid`.  The path to the file can then be built using `run_file`.\n",
    "\n",
    "``` python\n",
    ">>> fil = run_file(base=\"Q:\\E11_atmos\\data\", rid='20171127_155753')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But for this example we'll use the example data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "fil = os.path.join(os.getcwd(), 'example_data', 'laser_data.h5')\n",
    "# read hdf5 file\n",
    "h5 = H5Data(fil)\n",
    "h5.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `h5` is an instance of the H5Data class.  Creating this instance generates a `pandas.DataFrame` summary of the group attributes called `h5.log`. \n",
    "\n",
    "Usually it's a good idea to specify an `out_dire` when creating the instance,\n",
    "\n",
    "``` python\n",
    ">>> h5 = H5Data(fil, out_dire='analysis')\n",
    "```\n",
    "\n",
    "If `out_dire` is declared then the log can be cached as a pickle file.  When loading an instance H5Data checks to see if this cache already exists and won't rebuild the log if it does, which could otherwise take a long time for large files accessed over a slow network.\n",
    "\n",
    "Another use of `out_dire` is for quickly building useful paths, e.g., for saving plots to a sub directory.\n",
    "\n",
    "``` python\n",
    ">>> out_fil = h5.sub_dire('plots', fname='signal.png')\n",
    ">>> plt.savefig(out_fil, bbox_inches='tight', dpi=200)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our case building the log doesn't take very long.\n",
    "%time h5.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log output\n",
    "h5.log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental settings are stored in the log file as VARS and measurements as RECS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from e11.tools import add_column_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine VAR and REC data\n",
    "df = add_column_index(h5.var, 'VAR').join(add_column_index(h5.rec, 'REC'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# data\n",
    "xvals = df[('VAR', 'WL?1')]    # laser wavelength PID reference\n",
    "yvals = df[('REC', 'WLM?2')]   # measured wavelength\n",
    "ax.scatter(xvals, yvals, marker='.')\n",
    "\n",
    "# format\n",
    "ax.set_xlim([xvals.min(), xvals.max()])\n",
    "ax.set_ylim([yvals.min(), yvals.max()])\n",
    "ax.set_xlabel('set wavelength (nm)')\n",
    "ax.set_ylabel('measured wavelength (nm)')\n",
    "\n",
    "# output\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "The hdf5 datafile exists to store datasets.  In our case, these are distributed within groups. Each group represents one configuration of experimental variables (VARS), and they are numbered sequentually by the `squid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h5.squids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the datasets in a particular group\n",
    "squid = 1\n",
    "print(h5.datasets(squid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "See 'Raw datasets.ipynb' for examples for how to access different types of hdf5 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
